{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuestionDetector.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "18HVJsNC-WFnvVh7TBXCc5QRhEMLOeWwD",
      "authorship_tag": "ABX9TyOeVXqlnR7ErIhQIL1gG+5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daveshap/QuestionDetector/blob/main/QuestionDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfJ2yUQHfKEa"
      },
      "source": [
        "# Compile Training Data\n",
        "Note: Generate the raw data with [this notebook](https://github.com/daveshap/QuestionDetector/blob/main/DownloadGutenbergTop100.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b76g2sbfHqV"
      },
      "source": [
        "import re\n",
        "import random\n",
        "\n",
        "datafile = '/content/drive/My Drive/Gutenberg/sentence_data.txt'\n",
        "corpusfile = '/content/drive/My Drive/Gutenberg/corpus_data.txt'\n",
        "testfile = '/content/drive/My Drive/Gutenberg/test_data.txt'\n",
        "sample_cnt = 3000\n",
        "test_cnt = 30\n",
        "\n",
        "questions = list()\n",
        "exclamations = list()\n",
        "other = list()\n",
        "\n",
        "with open(datafile, 'r', encoding='utf-8') as infile:\n",
        "  body = infile.read()\n",
        "sentences = re.split('\\n\\n', body)\n",
        "\n",
        "for i in sentences:\n",
        "  if 'í' in i or 'á' in i:\n",
        "    continue \n",
        "  if '?' in i:\n",
        "    questions.append(i)\n",
        "  elif '!' in i:\n",
        "    exclamations.append(i)\n",
        "  else:\n",
        "    other.append(i)\n",
        "\n",
        "def flatten_sentence(text):\n",
        "  text = text.lower()\n",
        "  fa = re.findall('[\\w\\s]',text)\n",
        "  return ''.join(fa)\n",
        "\n",
        "\n",
        "def compose_corpus(data, count, label):\n",
        "  result = ''\n",
        "  random.seed()\n",
        "  subset = random.sample(data, count)\n",
        "  for i in subset:\n",
        "    result += '<|SENTENCE|> %s <|LABEL|> %s <|END|>\\n\\n' % (flatten_sentence(i), label)\n",
        "  return result\n",
        "\n",
        "corpus = compose_corpus(questions, sample_cnt, 'question')\n",
        "corpus += compose_corpus(exclamations, sample_cnt, 'other')\n",
        "corpus += compose_corpus(other, sample_cnt, 'other')\n",
        "\n",
        "with open(corpusfile, 'w', encoding='utf-8') as outfile:\n",
        "  outfile.write(corpus)\n",
        "print('Done!', corpusfile)\n",
        "\n",
        "corpus = compose_corpus(questions, test_cnt, 'question')\n",
        "corpus += compose_corpus(exclamations, test_cnt, 'other')\n",
        "corpus += compose_corpus(other, test_cnt, 'other')\n",
        "\n",
        "with open(testfile, 'w', encoding='utf-8') as outfile:\n",
        "  outfile.write(corpus)\n",
        "print('Done!', testfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtIXmjYAhB07"
      },
      "source": [
        "# Finetune Model\n",
        "Finetune GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrhH2Eoxk8ra"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0 --quiet\n",
        "!pip install gpt-2-simple --quiet\n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "\n",
        "# note: manually mount your google drive in the file explorer to the left\n",
        "\n",
        "model_dir = '/content/drive/My Drive/GPT2/models'\n",
        "checkpoint_dir = '/content/drive/My Drive/GPT2/checkpoint'\n",
        "#model_name = '124M'\n",
        "model_name = '355M'\n",
        "#model_name = '774M'\n",
        "\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name, model_dir=model_dir)\n",
        "print('\\n\\nModel is ready!')\n",
        "\n",
        "run_name = 'QuestionDetector'\n",
        "step_cnt = 4000\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=corpusfile,\n",
        "              model_name=model_name,\n",
        "              model_dir=model_dir,\n",
        "              checkpoint_dir=checkpoint_dir,\n",
        "              steps=step_cnt,\n",
        "              restore_from='fresh',  # start from scratch\n",
        "              #restore_from='latest',  # continue from last work\n",
        "              run_name=run_name,\n",
        "              print_every=50,\n",
        "              sample_every=1000,\n",
        "              save_every=1000\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKlcLStVlcvQ"
      },
      "source": [
        "# Test Results\n",
        "\n",
        "| Run | Model | Steps | Samples | Last Loss | Avg Loss | Accuracy |\n",
        "|---|---|---|---|---|---|---|\n",
        "| 01 | 124M | 2000 | 9000 | 0.07 | 0.69 | 71.4% |\n",
        "| 02 | 355M | 2000 | 9000 | 0.24 | 1.63 | 66% |\n",
        "| 03 | 355M | 4000 | 9000 | 0.06 | 0.83 | 58% |\n",
        "| 04 | 355M | 4000 | 9000 | 0.11 | 0.68 | 74.4% |\n",
        "\n",
        "Larger models seem to need more steps and/or data. Seems to perform very high on questions and less good on others. Test 04 was reduced to 2 classes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywrjxls9leZo"
      },
      "source": [
        "right = 0\n",
        "wrong = 0\n",
        "\n",
        "print('Loading test set...')\n",
        "with open(testfile, 'r', encoding='utf-8') as file:\n",
        "  test_set = file.readlines()\n",
        "\n",
        "for t in test_set:\n",
        "  t = t.strip()\n",
        "  if t == '':\n",
        "    continue\n",
        "  prompt = t.split('<|LABEL|>')[0] + '<|LABEL|>'\n",
        "  expect = t.split('<|LABEL|>')[1].replace('<|END|>', '').strip()\n",
        "  #print('\\nPROMPT:', prompt)\n",
        "  response = gpt2.generate(sess, \n",
        "                           return_as_list=True,\n",
        "                           length=30,  # prevent it from going too crazy\n",
        "                           prefix=prompt,\n",
        "                           model_name=model_name,\n",
        "                           model_dir=model_dir,\n",
        "                           truncate='\\n',  # stop inferring here\n",
        "                           include_prefix=False,\n",
        "                           checkpoint_dir=checkpoint_dir,)[0]\n",
        "  response = response.strip()\n",
        "  if expect in response:\n",
        "    right += 1\n",
        "  else:\n",
        "    wrong += 1\n",
        "  print('right:', right, '\\twrong:', wrong, '\\taccuracy:', right / (right+wrong))\n",
        "  #print('RESPONSE:', response)\n",
        "\n",
        "print('\\n\\nModel:', model_name)\n",
        "print('Samples:', max_samples)\n",
        "print('Steps:', step_cnt)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}